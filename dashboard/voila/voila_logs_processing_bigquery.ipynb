{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208e01bb-22cf-4059-978a-a5a8dc806c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all packages\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import re\n",
    "from urllib.parse import urlparse, parse_qsl, unquote\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import math\n",
    "import numpy as np\n",
    "import datetime \n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "from IPython.display import display\n",
    "import plotly.graph_objects as go \n",
    "import plotly.express as px\n",
    "import asyncio\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f633b44b-6ec8-4fdc-82f8-2d6354857311",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install google-cloud-bigquery\n",
    "!pip install pandas-gbq\n",
    "\n",
    "# Authenticate to GCP in the shell, like this:\n",
    "# gcloud auth application-default login\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from pandas.io import gbq\n",
    "\n",
    "import os\n",
    "current_dir = \"/home/jovyan/datahub-usage-analysis/dashboard\"\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=current_dir+\"xxx.json\"\n",
    "\n",
    "# Set up BigQuery client\n",
    "project_id = 'ucb-datahub-2018'\n",
    "client = bigquery.Client(project=project_id)\n",
    "\n",
    "# Define SQL query\n",
    "# replace the FROM... with the BigQuery table you want to query\n",
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM `ucb-datahub-2018.datahub_fa24.stderr_*`\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8491fc76-31af-4d5c-a879-ea930f705505",
   "metadata": {},
   "source": [
    "#opens up fall dataset\n",
    "nbgitpuller_fall23 = '/home/jovyan/discovery-su24-dataset/nbgitpuller-clicks-fall-2023.jsonl.gz'\n",
    "nbgitpuller_fall23 = pd.read_json(gzip.open(nbgitpuller_fall23), lines = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bfd652-21b6-41e5-8dcd-234b3dbdfacc",
   "metadata": {},
   "source": [
    "# opens up spring dataset\n",
    "nbgitpuller_filename = '/home/jovyan/discovery-su24-dataset/nbgitpuller-clicks-sp24.jsonl.gz'\n",
    "nbgitpuller_sp24 = pd.read_json(gzip.open(nbgitpuller_filename), lines = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96dae03-f1fc-4642-a1e3-242674431825",
   "metadata": {},
   "source": [
    "# combining both datasets, spring first then fall \n",
    "nbgitpuller_df = pd.concat([nbgitpuller_sp24, nbgitpuller_fall23], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb13502-1721-48a9-bffd-a9d83d0a63eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute query and load data into DataFrame\n",
    "nbgitpuller_df = gbq.read_gbq(query, project_id=project_id)\n",
    "\n",
    "nbgitpuller_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5495c05a-cf59-49b1-8485-984d6459f9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbgitpuller_df.to_csv(\"nbgitpuller_su24.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d901ca85-f6cd-4fb8-8c4c-a265a2b493f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtaining substring after GET and before the redirection\n",
    "urls_all = nbgitpuller_df.textPayload.apply(lambda x: x[x.find('GET')+3:x.find('->')].strip())\n",
    "\n",
    "# uses urllib.parse to parse the url into path and query\n",
    "urls_parsed_all = urls_all.apply(lambda x: urlparse(x))\n",
    "\n",
    "# uses the parsed urls to obtain the action from the path\n",
    "nbgitpuller_df['actions'] = urls_parsed_all.apply(lambda x: os.path.basename(x.path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac13f7c-6976-4274-b923-fdb4eacac1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to determine the filetypes\n",
    "def path_extension_puller(row):\n",
    "    \"\"\"\n",
    "    pandas row function; uses apply\n",
    "    function to pull out select file extensions and urlpaths\n",
    "    \"\"\"\n",
    "    row_dict = dict(row)\n",
    "    if 'urlpath' in row_dict:\n",
    "        key = 'urlpath'\n",
    "    elif 'subPath' in row_dict:\n",
    "        key = 'subPath'\n",
    "    else: \n",
    "        return 'NaN', 'NaN'\n",
    "    \n",
    "    # files that the analysis is interested in \n",
    "    file_extension_list = ['ipyn[b]?', 'Rmd', 'pdf', 'txt', 'xml', 'ini', 'csv', 'py', 'R', 'md']\n",
    "    if len(row_dict[key].split('.')) > 1:\n",
    "        file_extension_split_string = row_dict[key].split('.')[-1]\n",
    "        for file_extension in file_extension_list:\n",
    "            if (len(re.findall(file_extension, file_extension_split_string)) > 0):\n",
    "                return row_dict[key], re.findall(file_extension, file_extension_split_string)[-1]\n",
    "        else:\n",
    "            return row_dict[key], 'NaN'\n",
    "    else:\n",
    "            return row_dict[key], 'NaN'\n",
    "\n",
    "def get_repo(row):\n",
    "    \"\"\"\n",
    "    pandas row function; uses apply\n",
    "    returns repo url from parsed url\n",
    "    \"\"\"\n",
    "    for item in row:\n",
    "        key, value = item\n",
    "        if 'repo' in key:\n",
    "            return unquote(value)\n",
    "    return 'NaN'\n",
    "\n",
    "def repo_parsing(row):\n",
    "    \"\"\"\n",
    "    pandas row function; uses apply\n",
    "    parses the repo url so that it obtains the user and folder/content user is accessing\n",
    "    \"\"\"\n",
    "    if row:\n",
    "        if len(row[0].split('/')) > 2:\n",
    "            return row[0].split('/')[1]\n",
    "        else:\n",
    "            return row[0].split('/')[-1]\n",
    "    else:\n",
    "        return 'NaN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1c0236-54bb-44ca-acde-f548e492c95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# makes a new dataframe that only contains git-pull and resets index\n",
    "nbgitpuller_df_pull = nbgitpuller_df[nbgitpuller_df.actions == 'git-pull'].reset_index()\n",
    "\n",
    "# obtains all the log info\n",
    "log_info_pull = nbgitpuller_df_pull.textPayload.apply(lambda x: ''.join(re.findall(\"\\[.*\\]\", x)).replace('[', '').replace(']', '').split(' '))\n",
    "\n",
    "# retreives the hubs for each textpayload\n",
    "hub_source_pull = nbgitpuller_df_pull.resource.apply(lambda x: x['labels']['namespace_name'])\n",
    "\n",
    "# obtains substring after GET and before the redirection\n",
    "urls_pull = nbgitpuller_df_pull.textPayload.apply(lambda x: x[x.find('GET')+3:x.find('->')].strip())\n",
    "\n",
    "# uses urllib.parse to parse the url into path and query\n",
    "urls_parsed_pull = urls_pull.apply(lambda x: urlparse(x))\n",
    "\n",
    "# uses parsed urls to obtain the action as a quality check\n",
    "actions_pull = urls_parsed_pull.apply(lambda x: os.path.basename(x.path))\n",
    "\n",
    "# breaks apart the parsed query into repo/urlpath\n",
    "urls_queries_pull = urls_parsed_pull.apply(lambda x: parse_qsl(x.query))\n",
    "\n",
    "# getting the file type from urlpath\n",
    "path_extension_pull = urls_queries_pull.apply(path_extension_puller)\n",
    "\n",
    "# gets repo urls from the parsed url\n",
    "repos_pull = urls_queries_pull.apply(get_repo)\n",
    "\n",
    "# extract ones that have github.com in the repo url or else its a null value\n",
    "repos_parsed_pull = repos_pull.apply(lambda x: re.findall(\"github\\.com/+(.+)\", x) if x else 'NaN')\n",
    "\n",
    "# obtains the user and git content from github.com repo urls\n",
    "git_user_pull = repos_parsed_pull.apply(lambda x: x[0].split('/')[0] if x else 'NaN')\n",
    "git_user_repo_pull = repos_parsed_pull.apply(repo_parsing)\n",
    "\n",
    "# adds it all into a dataframe\n",
    "nbgitpuller_textPayload_df_pull = pd.DataFrame({'log_info_type': log_info_pull.apply(lambda x: x[0]),\n",
    "                                           'timestamp_date': log_info_pull.apply(lambda x: x[1]),\n",
    "                                           'timestamp_time': log_info_pull.apply(lambda x: x[2]),\n",
    "                                           'action': actions_pull,\n",
    "                                           'git_query': urls_queries_pull,\n",
    "                                           'repo': repos_pull,\n",
    "                                           'git_user_content': repos_parsed_pull,\n",
    "                                           'git_user': git_user_pull,\n",
    "                                           'git_content': git_user_repo_pull,\n",
    "                                           'git_path': path_extension_pull.apply(lambda x: x[0]),\n",
    "                                           'file_extension': path_extension_pull.apply(lambda x: x[1]),\n",
    "                                           'hub': hub_source_pull})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ac3620-2690-4a12-9ff1-cdfb9665cb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbgitpuller_textPayload_df_pull['git_user_content_path'] = nbgitpuller_textPayload_df_pull.apply(lambda x: ''.join(x['git_user_content']) + '/' + ''.join(x['git_path']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea83c1e-e524-44ac-9383-af5494e92b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def course_assigner_regex(row):\n",
    "    \"\"\"\n",
    "    pandas row function; uses apply\n",
    "    determines which classes and semesters are for each github repo\n",
    "    \"\"\"\n",
    "    courses = {'(data8|ds8)': 'data8', '(ds100|data100)': 'data100', '(prob140)': 'data140', #data\n",
    "               '(caldataeng|data101|ds101)': 'data101', '(data6|ds6)': 'data6', '(data102|ds102)': 'data102', #data\n",
    "               '(data4ac|ds4ac)': 'data4ac', '(data198|ds198)': 'data198',\n",
    "               '(cs189|compsci189)': 'compsci189', '(cs170|compsci170)': 'compsci170', #compsci \n",
    "               '(ee16a|eecs16a)': 'eecs16a', '(ee16b|eecs16b)': 'eecs16b', '(eecs127)': 'eecs127',#eecs\n",
    "               '(ee120|eleng120)': 'eleng120', #electrical engineering\n",
    "               '(physics111b)': 'physics111b', '(physics88)': 'physics88', # physics\n",
    "               '(polsci3|ps3|polisci3)': 'polsci3', '(polsci5|ps5)': 'polsci5', '(polsci88|ps88)': 'polsci88', '(ps109|polsci109)': 'polsci109', # polisci\n",
    "               '(ce190|civeng90)': 'civgeng190', '(ce93|civeng93)': 'civeng93', '(ce200b|civeng200b)': 'civeng200b', '(ce110|civeng110)': 'civeng110', #civileng\n",
    "               '(envecon118|eep118)': 'envecon118', '(eep147|envecon147)': 'envecon147', '(eep153|envecon153)': 'envecon153', #environmental\n",
    "               'ph[w]?142': 'pbhlth142', 'ph[w]?251': 'pbhlth251', 'ph[w]?290': 'pbhlth290', 'ph[w]?252': 'pbhlth252', 'ph[w]?253': 'pbhlth253', 'pbhlth250c': 'pbhlth250c',\n",
    "               'ph[w]?196': 'pbhlth196', # public health\n",
    "               'mcb163l': 'mcellbi163l', 'mcb280': 'mcellbi280', 'mcbc117': 'mcellbic117', 'mcb32': 'mcellbi32', 'mcb288': 'mcellbi288', #molecular cell bio\n",
    "               '(bio1b|biology1b)': 'biology1b', # biology\n",
    "               'stat88': 'stat88', 'stat157': 'stat157', 'stat159': 'stat159', 'stat131': 'stat131', 'stat135': 'stat135', 'stat20': 'stat20', \n",
    "               'stat150': 'stat150', #stat\n",
    "               'math124': 'math124', #math\n",
    "               '(demog180)': 'demog180', 'demog[c]?175': 'demog175', #demography\n",
    "               '(eps130)': 'eps130', '(eps88)': 'eps88', 'eps256': 'eps256', 'eps24': 'eps24',\n",
    "               '(econ140)': 'econ140', '(econ148)': 'econ148', 'econ141': 'econ141', 'econ172': 'econ172', 'econ151': 'econ151', #econ\n",
    "               'econ157': 'econ157', 'econ130': 'econ130', 'econ143': 'econ143', 'econ135': 'econ135',\n",
    "               '(rbridge)': 'datasci_rbridge', '(midsw241)': 'datasci241', '(midsw203)': 'datasci203', #datasci\n",
    "               '(legal123|legalst123)': 'legalst123', '(legalst190|legal190)': 'legalst190', # legal\n",
    "               '(es22ac|ethstd22ac)': 'ethstd22ac', '(esc164a|ethstdc164a)': 'ethstdc164a', '(es21ac|ethstd21ac)': 'ethstd21ac',  # ethnic studies\n",
    "               'cp201b': 'cyplan201b', '(cityplanning88|cp88)': 'cyplan88', \n",
    "               'ib120': 'integbi120', 'ibc32': 'integbi32', 'ib134l': 'integbi134l',\n",
    "               'mse104l': 'matsci104l',\n",
    "               'are212': 'aresec212',\n",
    "               'educw142': 'educw142',\n",
    "               '(cogscic131|psych123)': 'cogscic131', 'psych198': 'psych198',\n",
    "               'anth[ro]?115': 'anthro115',\n",
    "               'espmc167': 'espmc167', '(ibespm105)': 'espmc105',\n",
    "               'ls88': 'ls88',\n",
    "               'dighum101': 'dighum101', 'dighum160': 'dighum160',\n",
    "               'plantbi135': 'plantbi135',\n",
    "               'hist160': 'history160',\n",
    "               'soc88': 'sociol88', 'sw282': 'socwel282',\n",
    "               'music30': 'music30', 'artw23ac': 'artw23ac'} \n",
    "    # hard coded\n",
    "    git_content_user = {'danielabrahamgit120': 'eleng120', 'evalencialopezw142': 'educw142', 'charismasacey[A-Za-z0-9]+cp201': 'cp201a'}\n",
    "\n",
    "    #strips anything thats not a letter or number\n",
    "    git_string_cleaned = re.sub(r'[^a-zA-Z0-9]', '', ''.join(row)).lower()\n",
    "    for key in courses:\n",
    "        if re.findall(key, git_string_cleaned):\n",
    "            return courses[key]\n",
    "    for key in git_content_user:\n",
    "        if re.findall(key, git_string_cleaned):\n",
    "            return git_content_user[key]\n",
    "    else:\n",
    "        return 'unknown'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc471691-1af0-4e44-b4cf-2a524d716b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigns classes/courses to each log\n",
    "nbgitpuller_textPayload_df_pull['course'] = nbgitpuller_textPayload_df_pull.git_user_content_path.apply(course_assigner_regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec36a016-32be-4c25-9dda-c73f44781151",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semester_assigner_regex(row):\n",
    "    \"\"\"\n",
    "    pandas row function; uses apply\n",
    "    returns the semester of the course material if known\n",
    "    \"\"\"\n",
    "    semester = [r'fa[ll]*\\d{1,4}', r'su[mmer]*\\d{1,4}', r'sp[ring]*\\d{1,4}', r'\\d{1,4}fa[ll]', r'\\d{1,4}su[mmer]*', r'\\d{1,4}sp[ring]*']\n",
    "    sem_match_dict = {'sp': 'spring', 'fa': 'fall', 'su':'summer'}\n",
    "\n",
    "    git_string_cleaned = re.sub(r'[^a-zA-Z0-9]', '', ''.join(row)).lower()\n",
    "\n",
    "    year_range = [2018, datetime.datetime.now().year]\n",
    "\n",
    "    for sem in semester:\n",
    "        try:\n",
    "            if re.findall(sem, git_string_cleaned):\n",
    "                sem_match = re.findall(sem, git_string_cleaned)[-1]\n",
    "                sem_match_split = re.split('(\\d+)', sem_match)\n",
    "                sem_char = re.findall('[a-z]+', sem_match)[-1]\n",
    "                sem_year = re.findall('[0-9]+', sem_match)[-1]\n",
    "                for key, value in sem_match_dict.items():\n",
    "                    if key in sem_char and sem_match_split[-1] == '':\n",
    "                        if len(sem_year) < 4:\n",
    "                            if year_range[0] <= int(f'20{sem_year[-2:]}') <= year_range[1]:\n",
    "                                return f'{value}20{sem_year[-2:]}'\n",
    "                            else:\n",
    "                                return \n",
    "                        elif len(sem_year) == 4:\n",
    "                            if year_range[0] <= int(sem_year) <= year_range[1]:\n",
    "                                return f'{value}{sem_year}'\n",
    "                            else:\n",
    "                                return 'unknown'\n",
    "                    elif key in sem_char and sem_match_split[-1] != '':\n",
    "                        if year_range[0] <= int(sem_year) <= year_range[1]:\n",
    "                            return f'{value}{sem_year}'\n",
    "                        else:\n",
    "                            return 'unknown'\n",
    "        except Exception as e:\n",
    "            print(f\"Failed findall: {e=} {sem=} {git_string_cleaned=}\")\n",
    "            continue\n",
    "    else:\n",
    "        return 'unknown'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf7b5c5-9c9d-48e8-85d4-e320ee136d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigns a semester to each log\n",
    "nbgitpuller_textPayload_df_pull['semester'] = nbgitpuller_textPayload_df_pull.git_user_content_path.apply(semester_assigner_regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110d17f4-6bf4-4570-91a4-191adbd2aae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforms timestamp into one and converts from UTC to PST\n",
    "nbgitpuller_textPayload_df_pull['timestamp_date_time_pst'] = pd.to_datetime(nbgitpuller_textPayload_df_pull.timestamp_date + ' ' + nbgitpuller_textPayload_df_pull.timestamp_time) - pd.Timedelta(8, unit = 'h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcd4c0d-beb3-4e77-a976-28538a3d6619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ones that have NaN as their filetype, check if git_path contains r_studio\n",
    "nbgitpuller_textPayload_df_pull['file_extension'] = nbgitpuller_textPayload_df_pull.apply(lambda x: 'rstudio' if 'rstudio' in x['git_path'] else x['file_extension'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226424f9-db99-4d96-9aec-d48cc2d95256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determines if the links are github or non-github\n",
    "nbgitpuller_textPayload_df_pull['abnormal'] = nbgitpuller_textPayload_df_pull.repo.apply(lambda x: 'N' if 'github.com' in x else 'Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380d68e6-f1b1-4673-bc6d-48d8ec6334d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbgitpuller_textPayload_df_pull.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f835edc-1a70-4144-9596-e3cfe5f803df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separates abnormal repos \n",
    "nbgitpuller_textPayload_df_pull_abnormal = nbgitpuller_textPayload_df_pull[nbgitpuller_textPayload_df_pull.abnormal == 'Y']\n",
    "nbgitpuller_textPayload_df_pull_normal = nbgitpuller_textPayload_df_pull[nbgitpuller_textPayload_df_pull.abnormal == 'N']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8ea788-bc77-4d4d-8a92-3c25e040735c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec6865b-4f7b-40ce-a89c-cd776ff2e72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame to a pickle file\n",
    "with open('nbgitpuller_df_serialized.pkl', 'wb') as file:\n",
    "    pickle.dump(nbgitpuller_textPayload_df_pull_normal, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338d5c79-9e93-464b-815a-ee1a0689f21c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save DataFrame to a pickle file\n",
    "with open('nbgitpuller_df_abnormal_serialized.pkl', 'wb') as file:\n",
    "    pickle.dump(nbgitpuller_textPayload_df_pull_abnormal, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
