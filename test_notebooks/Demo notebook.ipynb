{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Introduction to Enterprise Colab in BigQuery Studio","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Generate customer clusters and marketing messages with BigQuery DataFrames and GenAI\n","\n","##Overview\n","Within the **BigQuery Studio** workspace, you can use a Colab Enterprise notebook interface and a workspace to save and share your notebooks. The notebooks come with **BigQuery DataFrames**, which provide a Pythonic DataFrame and ML API powered by the BigQuery engine. The operations happen in BigQuery at scale rather than within the notebook runtime.\n","\n","*   [bigframes.pandas](https://cloud.google.com/python/docs/reference/bigframes/latest/bigframes.dataframe.DataFrame) provides a pandas-compatible API for analytics.\n","*   [bigframes.ml](https://cloud.google.com/python/docs/reference/bigframes/latest/bigframes.ml.cluster) provides a scikit-learn-like API for ML.\n","*   [bigframes.ml.llm](https://cloud.google.com/python/docs/reference/bigframes/latest/bigframes.ml.llm) provides LLM capabilities.\n","\n","BigQuery DataFrames is an open-source Python package. It is pre-installed on  BigQuery Studio Python notebooks.  Additionally, you can always run `pip install --upgrade bigframes` to install the latest version.\n","\n","\n","\n","## Objectives\n","This example illustrates a common Data to AI journey from data exploration to constructing a k-means machine learning model with BigFrames to segment customers of similar behaviors and demographics. Subsequently, Generative AI is applied to leverage cluster information and customer messaging to activate marketing campaigns. In doing so, you can build a data-centric, personalized marketing campaign all from BigQuery!\n","\n","In this tutorial, you will:\n","\n","* Generate features using BigQuery DataFrames\n","* Perform basic data exploration\n","* Implement a k-means clustering model with BigFrames\n","* Produce cluster descriptive statistics\n","* Utilize Generative AI to articulate ML model outputs in natural language for business users\n","* (Bonus) Use Generative AI to craft engaging emails tailored to customer segments.\n","\n","\n","\n","\n","###Helpful Links\n","\n","* [BigFrames API Reference](https://cloud.google.com/python/docs/reference/bigframes/latest)\n","\n","\n","* [BigFrames GitHub page with sample notebooks](https://github.com/googleapis/python-bigquery-dataframes)\n","\n","* [Troubleshooting notebook runtimes](https://cloud.google.com/colab/docs/troubleshooting)\n"],"metadata":{"id":"Sxq-V_jV4gEk"}},{"cell_type":"markdown","source":["## Before you Begin : Setup Steps\n"],"metadata":{"id":"05KJTULrIrbP"}},{"cell_type":"markdown","source":["## Install the `bigframes` package."],"metadata":{"id":"Fo3s2ujertLo"}},{"cell_type":"code","source":["!pip install --upgrade bigframes"],"metadata":{"id":"SNJdanrQM0IT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Define notebook variables\n","\n","Please update variables like your GCP Project ID (`PROJECT_ID`), dataset name (`DATASET_NAME`), and location (`LOCATION`).\n","\n","The variables `DATASET_NAME`, `LOCATION` and `MODEL_NAME` are pre-populated, but you can update them if you wish.\n","\n","Ensure that the dataset exists in the same GCP Project as `PROJECT_ID`."],"metadata":{"id":"sHoUOuxf5GOR"}},{"cell_type":"code","source":["#@title Setup Project Variables { run: \"auto\", display-mode: \"form\" }\n","PROJECT_ID = \"ucb-datahub-2018\" #@param {type:\"string\"}\n","DATASET_NAME = \"theLook_retail\" #@param {type:\"string\"}\n","MODEL_NAME = \"bqdf_customer_segment_cluster\" #@param {type:\"string\"}\n","EVAL_NAME = MODEL_NAME + \"_eval\"\n","LOCATION = \"US\"  # @param {type:\"string\"}\n","from google.cloud import bigquery\n","client = bigquery.Client()"],"metadata":{"id":"_3Rfhx874F2J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset = client.create_dataset(DATASET_NAME, timeout=30)  # Make an API request.\n","print(\"Created dataset {}.{}\".format(client.project, dataset.dataset_id))"],"metadata":{"id":"wHJfWWBTumIu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"P-eLlA_0dj8p"}},{"cell_type":"markdown","source":["## Step 1 : Basic Exploratory Data Analysis\n","To kick things off, let's first inspect our data prior to constructing any models. Within this tutorial, we'll be working with the [theLook eCommerce public dataset](https://console.cloud.google.com/marketplace/product/bigquery-public-data/thelook-ecommerce).\n","\n","TheLook is an imaginary eCommerce apparel website. Within this dataset, you'll discover details about customers, products, orders, logistics, web events, and digital marketing campaigns. Our main emphasis is the `order_items` table, which contains transactional insights about customers. It's important to note that the contents of this dataset are artificially generated and are made available to professionals in the industry for the purposes of product exploration, testing, and assessment.\n","\n","There are a few ways we can query data and get it into a dataframe. Here are two approaches:"],"metadata":{"id":"IOlN-lku6KPi"}},{"cell_type":"markdown","source":["#### **Initializing BigQuery Dataframes**\n","\n","Import bigframes.pandas for a pandas-like interface. Use the Python SDK to bring data into a dataframe."],"metadata":{"id":"5Ss_JcgU6dxL"}},{"cell_type":"code","source":["import bigframes as bf\n","import bigframes.pandas as bpd"],"metadata":{"id":"QlW51RNDNEw-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["BigQuery DataFrames uses a BigQuery session internally to manage metadata on the service side. This session is tied to a location . BigQuery DataFrames uses the US multi-region as the default location, but you can use session_options.location to set a different location. Every query in a session is executed in the location where the session was created."],"metadata":{"id":"wEQpRmHws1WW"}},{"cell_type":"code","source":["bf.options.bigquery.project = PROJECT_ID\n","bf.options.bigquery.location = LOCATION"],"metadata":{"id":"qR-GYJlTORxf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["If you want to reset the location of the created DataFrame or Series objects, reset the session by executing `bf.close_session()`. After that, you can reuse `bf.options.bigquery.location` to specify another lo"],"metadata":{"id":"LlE01FGFsT8d"}},{"cell_type":"markdown","source":[" #### **`read_gbq` function**\n"," The `read_gbq` method accepts either a fully-qualified table ID or a SQL query."],"metadata":{"id":"Fugedzw5shoX"}},{"cell_type":"code","source":["df = bpd.read_gbq(\"bigquery-public-data.thelook_ecommerce.order_items\")\n","df"],"metadata":{"id":"RzXhD_KYNX25"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **Restricting Dataframe columns**\n","Next, Choosing a restricted set of features for the purpose of conducting feature engineering."],"metadata":{"id":"xC0_CcriIO9J"}},{"cell_type":"code","source":["df = df[[\"user_id\", \"order_id\", \"sale_price\", \"created_at\", \"status\"]].rename(columns={\"created_at\": \"order_created_date\"})\n","df"],"metadata":{"id":"kdNMJnBLOvi6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **Restricting the dataset to data spanning one year**"],"metadata":{"id":"HtznpFFnJZqO"}},{"cell_type":"code","source":["df = df[df[\"order_created_date\"] > \"2022-01-01\"]\n","df = df[df[\"order_created_date\"] < \"2023-01-01\"]\n","df"],"metadata":{"id":"9QVWdVT5PXmI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Step 2 : Feature Engineering using BigQuery Dataframes"],"metadata":{"id":"uIt9rmX4JTYW"}},{"cell_type":"markdown","source":["## Create features for k-means model.\n","\n","We intend to compute features such as the total number of orders per customer, average spending per customer, and the return ratio, calculated as the total number of returns divided by the number of orders."],"metadata":{"id":"8RDvQSsqrryy"}},{"cell_type":"markdown","source":["#### **Calculating total number of orders per customer**"],"metadata":{"id":"w1rh8N_rKFsU"}},{"cell_type":"code","source":["count_orders = df.groupby([\"user_id\"])[\"order_id\"].count()\n","count_orders"],"metadata":{"id":"GR47wGItaiXl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **Calculating average spend per customer**"],"metadata":{"id":"yFnCXVd9KNK5"}},{"cell_type":"code","source":["average_spend = df.groupby([\"user_id\"])[\"sale_price\"].mean()\n","average_spend"],"metadata":{"id":"tRPfIxrqa6O9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **Calculating total number of returned orders per customer**"],"metadata":{"id":"qcRAFUPnOZvD"}},{"cell_type":"code","source":["df[\"returned\"] = df[\"status\"] == \"Returned\"\n","returned = df.groupby([\"user_id\"])[\"returned\"].sum()\n","returned"],"metadata":{"id":"DYERzNIA9IJh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **Calculating return ratio per customer**"],"metadata":{"id":"VvfvSw0QOe9N"}},{"cell_type":"code","source":["return_ratio = returned / count_orders\n","return_ratio"],"metadata":{"id":"SUvwp6LIAuhc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **Compiling a conclusive dataframe for the development of a machine learning model for customer segmentation.**"],"metadata":{"id":"NBNq6Ub3Oik8"}},{"cell_type":"code","source":["df_customer = count_orders.rename(\"count_orders\").to_frame()\n","df_customer[\"average_spend\"] = average_spend\n","df_customer[\"return_ratio\"] = return_ratio\n","df_customer"],"metadata":{"id":"GMjuuLQg_eKh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Step 3 : Create a k-means model to cluster ecommerce data\n","\n","**K-means** is a widely used clustering algorithm that can dentify distinct groups or clusters within a dataset. With eCommerce data, k-means can segment customers, products, or transactions into meaningful groups for various analytical and business purposes.\n","\n","\n","#### **Cluster the customer data using BigFrames!**"],"metadata":{"id":"WnXQQOAc4t22"}},{"cell_type":"code","source":["from bigframes.ml.cluster import KMeans\n","from bigframes.ml.model_selection import train_test_split\n","\n","# Split test and training data\n","df_customer = df_customer.dropna()\n","train_X, test_X = train_test_split(df_customer, test_size = 0.2)\n","# train_X = train_X.drop(columns = [\"user_id\"])\n","# Create a K-Means cluster model\n","kmeans = KMeans(n_clusters = 5)\n","kmeans.fit(train_X)\n"],"metadata":{"id":"cWQ9botFf2Te"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **Save the model to BigQuery**"],"metadata":{"id":"iABA1HcDO4Wd"}},{"cell_type":"code","source":["kmeans.to_gbq(f\"{PROJECT_ID}.{DATASET_NAME}.{MODEL_NAME}\", True)"],"metadata":{"id":"8cMH1oeBB5jh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **Visualize the clusters**\n","\n","Next we'll visualize the k-means clusters on a scatterplot. We'll chart `days_since_last_order` by `average_spend` and color by segment/cluster_id generated from the model."],"metadata":{"id":"81nwv2QE-mlh"}},{"cell_type":"code","source":["#########################\n","#Plot K-Means clusters\n","#########################\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","\n","# Import K-Means predictions to dataframe\n","segments_df = kmeans.predict(df_customer)\n","segments_df = segments_df.rename(columns={'CENTROID_ID': 'segment_id'})\n","segments_pd = segments_df.sample(frac=0.2, random_state=1).to_pandas()\n","\n","segments_pd\n"],"metadata":{"id":"Ld5HJJlKGlXK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **Generate scatterplot to display clusters**"],"metadata":{"id":"CKIhpH9kPXNQ"}},{"cell_type":"code","source":["g = sns.lmplot(x='count_orders', y='average_spend', data=segments_pd, fit_reg=False, hue='segment_id', palette='Set2', height=7, aspect=2)\n","g = (g.set_axis_labels('Count Orders','Average Spend ($)', fontsize=15).set(xlim=(0,10),ylim=(0,400)))\n","plt.title('Attribute Grouped by K-means Cluster', pad=20, fontsize=20)"],"metadata":{"id":"WH8s_tULGyf5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **Cluster Summary Statistics**\n","\n","The visualization helped us see distinct clusters. Now let's generate some summary statistics around order recency, frequency, and spend by cluster."],"metadata":{"id":"yh1_PqPvIalu"}},{"cell_type":"code","source":["df_centroid = kmeans.cluster_centers_\n","df_centroid"],"metadata":{"id":"UmEsjTfeIueR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_centroid_pivot = df_centroid.pivot(index='centroid_id', columns='feature', values='numerical_value')\n","df_centroid_pivot"],"metadata":{"id":"FzVxofIPJ5zQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **Summary Statistics**\n","Whew! That's a lot of metrics and cluster info. How about we explain this to our colleagues using the magic of LLMs.\n","\n","Let's begin by creating a string with the summary statistics from the last cell."],"metadata":{"id":"9Ey4aZIEMykc"}},{"cell_type":"code","source":["pd_df = df_centroid_pivot.reset_index().to_pandas()\n","pd_df.to_string(header=False, index=False)\n","\n","cluster_info = []\n","for i, row in pd_df.iterrows():\n","  cluster_info.append(\"{0}, average spend ${2}, count of orders per person {1}, return ratio {3}\"\n","    .format(row[\"centroid_id\"], row[\"count_orders\"], row[\"average_spend\"], row[\"return_ratio\"]) )\n","\n","print(str.join(\"\\n\", cluster_info))"],"metadata":{"id":"XB8SdzclMxUx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Step 4 : Generative AI - Explain customer segments with Vertex AI PaLM API\n","\n","To leverage Large Language Models directly from BigQuery, we will specify a [BigQuery connection](https://cloud.google.com/bigquery/docs/working-with-connections). If you already have a connection, you can simplify provide the name and skip the following creation steps"],"metadata":{"id":"7Na0_rVVLhOk"}},{"cell_type":"code","source":["# Please fill in these values.\n","CONNECTION = \"bq-llm\"  # @param {type:\"string\"}\n","\n","connection_name = f\"{PROJECT_ID}.{LOCATION}.{CONNECTION}\""],"metadata":{"id":"W13HyzWX0I-F"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **BigQuery Connection Setup**\n","BigQuery lets you interact with services outside of BigQuery in Google Cloud services like Cloud Storage or Cloud Spanner, or in third-party sources like AWS or Azure. These external connections use the BigQuery Connection API.\n","\n","In this case, we interact with Vertex AI Large Language models using Connection API.\n","\n","In following cell, we try to use the provided connection, and if it doesn't exist, create a new one. We will also print the service account used.\n","\n","Note : You may require additional permissions as [documented here](https://cloud.google.com/bigquery/docs/working-with-connections#expandable-1) to perform following step."],"metadata":{"id":"EtiHiulOEd8R"}},{"cell_type":"code","source":["from google.cloud import bigquery_connection_v1 as bq_connection\n","from bigframes.ml.llm import PaLM2TextGenerator\n","session = bpd.get_global_session()"],"metadata":{"id":"sIqdPAl44JQc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Initialize client and set request parameters\n","client = bq_connection.ConnectionServiceClient()\n","new_conn_parent = f\"projects/{PROJECT_ID}/locations/{LOCATION}\"\n","exists_conn_parent = f\"projects/{PROJECT_ID}/locations/{LOCATION}/connections/{CONNECTION}\"\n","cloud_resource_properties = bq_connection.CloudResourceProperties({})\n","\n","# Try to connect using provided connection\n","try:\n","    request = client.get_connection(\n","        request=bq_connection.GetConnectionRequest(name=exists_conn_parent)\n","    )\n","    CONN_SERVICE_ACCOUNT = f\"serviceAccount:{request.cloud_resource.service_account_id}\"\n","# Create a new connection on error\n","except Exception:\n","    connection = bq_connection.types.Connection(\n","        {\"friendly_name\": CONNECTION, \"cloud_resource\": cloud_resource_properties}\n","    )\n","    request = bq_connection.CreateConnectionRequest(\n","        {\n","            \"parent\": new_conn_parent,\n","            \"connection_id\": CONNECTION,\n","            \"connection\": connection,\n","        }\n","    )\n","    response = client.create_connection(request)\n","    CONN_SERVICE_ACCOUNT = (\n","        f\"serviceAccount:{response.cloud_resource.service_account_id}\"\n","    )\n","# Set service account permissions\n","!gcloud projects add-iam-policy-binding {PROJECT_ID} --condition=None --no-user-output-enabled --member={CONN_SERVICE_ACCOUNT} --role='roles/bigquery.connectionUser'\n","!gcloud projects add-iam-policy-binding {PROJECT_ID} --condition=None --no-user-output-enabled --member={CONN_SERVICE_ACCOUNT} --role='roles/aiplatform.user'\n","!gcloud projects add-iam-policy-binding {PROJECT_ID} --condition=None --no-user-output-enabled --member={CONN_SERVICE_ACCOUNT} --role='roles/run.invoker'\n","\n","print(CONN_SERVICE_ACCOUNT)"],"metadata":{"id":"V8iLYPrX3opw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The resource connection service account requires certain project-level permissions:\n","\n","`roles/aiplatform.user` and `roles/bigquery.connectionUser`: These roles are required for the connection to create a model definition using the LLM model in Vertex AI ([documentation](https://cloud.google.com/bigquery/docs/generate-text#give_the_service_account_access)).\n","roles/run.invoker: This role is required for the connection to have read-only access to Cloud Run services that back custom/remote functions ([documentation](https://cloud.google.com/bigquery/docs/remote-functions#grant_permission_on_function))."],"metadata":{"id":"j2x4dhJ8Fhtc"}},{"cell_type":"markdown","source":["#### **Define the Large Language model using BigFrames**\n","\n","Use bigframes.ml.llm to define the model and get BigFrames session\n"],"metadata":{"id":"-ay0KygzF_Q1"}},{"cell_type":"markdown","source":["#### **Create a Prompt**\n","For each cluster, ask the LLM to act as a brand strategist and generate the following:\n","* Title\n","* Persona\n","* Next Marketing Step"],"metadata":{"id":"tdoRB7RjLso6"}},{"cell_type":"code","source":["model = PaLM2TextGenerator(session=session, connection_name=connection_name)"],"metadata":{"id":"7J22pFpewG-M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["clusters = str.join(\"\\n\", cluster_info)\n","\n","prompt = f\"\"\"\n","You're a creative brand strategist, given the following clusters, come up with \\\n","creative brand persona, a catchy title, and next marketing action, \\\n","explained step by step.\n","\n","Clusters:\n","{clusters}\n","\n","For each Cluster:\n","* Title:\n","* Persona:\n","* Next Marketing Step:\n","\"\"\"\n","\n"],"metadata":{"id":"MYwQNH0ELu9y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **Prediction using Large Language model**"],"metadata":{"id":"X7wyE30HP4-U"}},{"cell_type":"code","source":["prompt_df = bpd.read_pandas(pd.DataFrame({'prompt': [prompt]}))\n","pred = model.predict(prompt_df, max_output_tokens=1024, temperature=0.55, top_p=0.8, top_k=40)\n","print(pred.iloc[0,0])"],"metadata":{"id":"wumJXJv2Qqg_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Voila! We've now used k-Means clustering to create groups of spenders and explain their profiles.**"],"metadata":{"id":"jqC5uUguaunY"}},{"cell_type":"markdown","source":["**Congratulations**! You have learned how to use **BigFrames** and manage each step of the process, including gathering data, data manipulation, and querying the LLM."],"metadata":{"id":"bi8SGY4__aEI"}},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"oFVRAN2wckHC"}},{"cell_type":"markdown","source":["#### **BONUS #1: LLM Prompt Engineering**\n","\n","Sometimes, though, you want a little bit extra.\n","\n","#### **Personalized marketing emails**\n","Think about using Generative AI to also generate personalized marketing emails using witty e-mail headline for marketing campaign targeted to their clusters of customers\n","\n","Reference: [Prompt Generation with Generative AI](https://cloud.google.com/blog/transform/prompt-debunking-five-generative-ai-misconceptions)."],"metadata":{"id":"5HEVHGmmRyGW"}},{"cell_type":"code","source":["cluster_info = str.join('\\n', cluster_info)\n","\n","prompt = f\"\"\"\n","Pretend you're a creative strategist, analyze the following clusters and come up with \\\n","creative brand persona for each that includes the detail of which Taylor Swift song is \\\n","likely to be their favorite, a summary of how this relates to their purchasing behavior, \\\n","and a witty e-mail headline for marketing campaign targeted to their group using \\\n","their predicted favorite song title.\n","\n","Clusters:\n","{cluster_info}\n","\n","\n","For each Cluster:\n","* Cluster:\n","* Interests:\n","* Favorite Taylor Swift Song:\n","* Witty email headline:\n","* Email body:\n","\n","\"\"\"\n"],"metadata":{"id":"3HgwtN1tR3xQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prompt_df = bpd.read_pandas(pd.DataFrame({'prompt': [prompt]}))\n","pred = model.predict(prompt_df, max_output_tokens=1024, temperature=0.55, top_p=0.8, top_k=40)\n","print(pred.iloc[0,0])"],"metadata":{"id":"PqkskS625o7y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **BONUS #2: Generate Python in your Notebook**\n","\n","If you have Gemini enabled on your project, you can begin to generate Python directly within your Notebook:\n","* Open a new Code cell\n","* Click \"Generate with AI\"\n","* Paste one of the prompts below and hit Enter\n","* Generate Python code should appear in the cell\n"],"metadata":{"id":"LT8lVXaCGDtK"}},{"cell_type":"code","source":["# prompt: 10 random numbers using numpy"],"metadata":{"id":"zLFewJ8iGbLz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# prompt: generate a bigframes dataframe from the table bigquery-public-data.thelook_ecommerce.order_items"],"metadata":{"id":"ysTumh3TkcYU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# prompt: write some sql that queries the table bigquery-public-data.thelook_ecommerce.order_items.  Don't use python. Use %%bigquery."],"metadata":{"id":"b3J4r9FXmPfs"},"execution_count":null,"outputs":[]}]}