{
 "cells": [
  {
   "cell_type": "raw",
   "id": "89e3876d",
   "metadata": {},
   "source": [
    "# ASSIGNMENT CONFIG\n",
    "\n",
    "solutions_pdf: false\n",
    "name: labXX\n",
    "files:\n",
    "    - resources\n",
    "generate: \n",
    "    pdf: false\n",
    "    filtering: true\n",
    "    pagebreaks: true\n",
    "check_all_cell: true\n",
    "requirements:\n",
    "    - matplotlib==3.7.2\n",
    "export_cell: \n",
    "    instructions: \"Make sure you submit the .zip file to Gradescope.\"\n",
    "    run_tests: false\n",
    "    pdf: false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7608a51a-6928-46db-a1f5-a1414515ceee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5af9dc94",
   "metadata": {},
   "source": [
    "# CE 93: Lab Assignment XX\n",
    "\n",
    "You must submit the lab to Gradescope by the due date. You will submit the zip file produced by running the final cell of the assignment.\n",
    "\n",
    "## About this Lab\n",
    "The objective of this assignment is to ... (COPY AND MODIFY FROM BCOURSES LAB QUIZZES)\n",
    "\n",
    "## Instructions \n",
    "**Run the first cell, Initialize Otter**, to import the autograder and submission exporter.\n",
    "\n",
    "Throughout the assignment, replace `...` with your answers. We use `...` as a placeholder and theses should be deleted and replaced with your answers.\n",
    "\n",
    "Any part listed as a \"<font color='red'>**Question**</font>\" should be answered to receive credit.\n",
    "\n",
    "**Please save your work after every question!**\n",
    "\n",
    "To read the documentation on a Python function, you can type `help()` and add the function name between parentheses.\n",
    "\n",
    "**Run the cell below**, to import the required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3463c41",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'resources'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mresources\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_hash\u001b[39m(num):\n\u001b[1;32m     20\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Helper function for assessing correctness\"\"\"\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'resources'"
     ]
    }
   ],
   "source": [
    "# Please run this cell, and do not modify the contents\n",
    "import math\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import statistics as stats\n",
    "import cmath\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import hashlib\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import FileUpload\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "import os\n",
    "import resources\n",
    "\n",
    "def get_hash(num):\n",
    "    \"\"\"Helper function for assessing correctness\"\"\"\n",
    "    return hashlib.md5(str(num).encode()).hexdigest()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97eac86e",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "...\n",
    "\n",
    "Most of the notebook text and code could be copied from the old notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b334f350",
   "metadata": {},
   "source": [
    "### Load the data\n",
    "\n",
    "Let's load the provided data set `<replace>`. These are all the features:\n",
    "\n",
    "(TABLE WITH FEATURES)\n",
    "\n",
    "* Load the data using the Pandas `pd.read_csv()` function\n",
    "\n",
    "Run the cell below, which reads the data and saves it as a variable named `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0844215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read a .csv file as a DataFrame\n",
    "df = pd.read_csv('<replace>')\n",
    "\n",
    "# returns the first 5 rows of the data set by default\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db995cc8",
   "metadata": {},
   "source": [
    "### Multiple Choice Question (One Answer Only)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2eca867f",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: qXXX\n",
    "points: XXX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857b6028",
   "metadata": {},
   "source": [
    "<font color='red'>**Question XXX.**</font> **\\<QUESTION\\>**? Assign your answer to the variable `<VARIABLE>` as a string. (XXX pts)\n",
    "\n",
    "**A.** ... \\\n",
    "**B.** ... \\\n",
    "**C.** ... \\\n",
    "**D.** ... \\\n",
    "**E.** ...\n",
    "\n",
    "Your answer should be a string, e.g., `\"A\"`, `\"B\"`, etc.\\\n",
    "Remember to put quotes around your answer choice."
   ]
  },
  {
   "cell_type": "raw",
   "id": "b28c4391",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daa7248",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ANSWER CELL\n",
    "qXXX = \"A\" # SOLUTION\n",
    "qXXX"
   ]
  },
  {
   "cell_type": "raw",
   "id": "db48f01d",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "id": "47e14dd4",
   "metadata": {},
   "source": [
    "# BEGIN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6f9cd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" # BEGIN TEST CONFIG\n",
    "points: 0\n",
    "success_message: Correct answer format.\n",
    "failure_message: Incorrect answer format. Make sure you only have the letter of your answer choice in quotes.\n",
    "\"\"\" # END TEST CONFIG\n",
    "\n",
    "assert len(qXXX) == 1\n",
    "assert isinstance(qXXX, str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2acf9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" # BEGIN TEST CONFIG\n",
    "points: XXX\n",
    "failure_message: Incorrect answer.\n",
    "\"\"\" # END TEST CONFIG\n",
    "\n",
    "assert get_hash(qXXX.upper()) == 'XXX'"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d69c343d",
   "metadata": {},
   "source": [
    "# END TESTS"
   ]
  },
  {
   "cell_type": "raw",
   "id": "74b676f0",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178314cf",
   "metadata": {},
   "source": [
    "### Multiple Choice Question (Multiple Answers)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f7078f83",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: qXXX\n",
    "points: XXX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e278144",
   "metadata": {},
   "source": [
    "<font color='red'>**Question XXX.**</font> **\\<QUESTION\\>**? Assign ALL that apply to the variable `<VARIABLE>`. (XXX pts)\n",
    "\n",
    "**A.** ... \\\n",
    "**B.** ... \\\n",
    "**C.** ... \\\n",
    "**D.** ... \\\n",
    "**E.** ...\n",
    "\n",
    "Answer in the next cell. Add each selected choice as a string and separate each two answer choices by a comma. For example, if you want to select `\"A\"` and `\"B\"`, your answer should be `\"A\", \"B\"`.\\\n",
    "Assign your answer to the given variable.\n",
    "Remember to put quotes around each answer choice."
   ]
  },
  {
   "cell_type": "raw",
   "id": "adaaaf40",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816a7484",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ANSWER CELL\n",
    "qXXX = \"A\", \"B\" # SOLUTION\n",
    "qXXX"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6fb5404c",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b45cbe2d",
   "metadata": {},
   "source": [
    "# BEGIN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26ebca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" # BEGIN TEST CONFIG\n",
    "points: 0\n",
    "success_message: Correct answer format.\n",
    "failure_message: Incorrect answer format. Make sure you only have the letter of your answer choice in quotes and answers are separated by commas.\n",
    "\"\"\" # END TEST CONFIG\n",
    "\n",
    "assert isinstance(qXXX, (tuple, str))\n",
    "assert all(isinstance(option, str) for option in qXXX)\n",
    "assert all(len(option) == 1 for option in qXXX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a23f363",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" # BEGIN TEST CONFIG\n",
    "points: XXX\n",
    "failure_message: Incorrect answer.\n",
    "\"\"\" # END TEST CONFIG\n",
    "\n",
    "assert get_hash(\"A\" in qXXX or \"a\" in qXXX) == 'XXX'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a109e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" # BEGIN TEST CONFIG\n",
    "points: XXX\n",
    "failure_message: Incorrect answer.\n",
    "\"\"\" # END TEST CONFIG\n",
    "\n",
    "assert get_hash(\"B\" in qXXX or \"b\" in qXXX) == 'XXX'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f644d348",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" # BEGIN TEST CONFIG\n",
    "points: XXX\n",
    "failure_message: Incorrect answer.\n",
    "\"\"\" # END TEST CONFIG\n",
    "\n",
    "assert get_hash(\"C\" in qXXX or \"c\" in qXXX) == 'XXX'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0545e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" # BEGIN TEST CONFIG\n",
    "points: XXX\n",
    "failure_message: Incorrect answer.\n",
    "\"\"\" # END TEST CONFIG\n",
    "\n",
    "assert get_hash(\"D\" in qXXX or \"d\" in qXXX) == 'XXX'"
   ]
  },
  {
   "cell_type": "raw",
   "id": "370f6d98",
   "metadata": {},
   "source": [
    "# END TESTS"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4b8440f7",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2da6ab3",
   "metadata": {},
   "source": [
    "### Numerical Answer"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ee3c2928",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: qXXX\n",
    "points: XXX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc88a53",
   "metadata": {},
   "source": [
    "<font color='red'>**Question XXX.**</font> **\\<QUESTION\\>**? Assign your answer to `<VARIABLE>`. Do not just manually type the numeric answer. Use Python expressions that return the desired answer and assign the expression to the variable. (XXX pts)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1a77348e",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9999ccc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ANSWER CELL\n",
    "qXXX = ... # SOLUTION\n",
    "f'TEXT: {qXXX:.3f}'"
   ]
  },
  {
   "cell_type": "raw",
   "id": "38be25c0",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "id": "50a25cb6",
   "metadata": {},
   "source": [
    "# BEGIN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7862632f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" # BEGIN TEST CONFIG\n",
    "points: XXX\n",
    "failure_message: Incorrect answer.\n",
    "\"\"\" # END TEST CONFIG\n",
    "\n",
    "assert get_hash(round(qXXX,10)) == 'XXX'"
   ]
  },
  {
   "cell_type": "raw",
   "id": "36e45a49",
   "metadata": {},
   "source": [
    "# END TESTS"
   ]
  },
  {
   "cell_type": "raw",
   "id": "013e644e",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69729eab",
   "metadata": {},
   "source": [
    "### Numerical Array"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9064fc10",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: qXXX\n",
    "points: XXX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73172d3",
   "metadata": {},
   "source": [
    "<font color='red'>**Question XXX.**</font> **\\<QUESTION\\>**? Assign your answer to `<VARIABLE>`. Do not just manually type the numeric answer. Use Python expressions that return the desired answer and assign the expression to the variable. (XXX pts)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "01b0449e",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3f421e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ANSWER CELL\n",
    "qXXX = ... # SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "id": "22eb459c",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "id": "333fa6cd",
   "metadata": {},
   "source": [
    "# BEGIN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa4bb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" # BEGIN TEST CONFIG\n",
    "points: XXX\n",
    "failure_message: Incorrect answer.\n",
    "\"\"\" # END TEST CONFIG\n",
    "\n",
    "assert get_hash(len(qXXX)) == 'XXX'\n",
    "assert get_hash(sum(qXXX)) == 'XXX'"
   ]
  },
  {
   "cell_type": "raw",
   "id": "17b8369a",
   "metadata": {},
   "source": [
    "# END TESTS"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c5b3c14a",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20bba6f",
   "metadata": {},
   "source": [
    "### You're done with this Lab!\n",
    "\n",
    "**Important submission information:** After completing the assignment, click on the Save icon from the Tool Bar &nbsp;<i class=\"fa fa-save\" style=\"font-size:16px;\"></i>&nbsp;. After saving your notebook, **run the cell with** `grader.check_all()` and confirm that you pass the same tests as in the notebook. Then, **run the final cell** `grader.export()` and click the link to download the zip file. Finally, go to Gradescope and submit the zip file to the corresponding assignment. \n",
    "\n",
    "**Once you have submitted, stay on the Gradescope page to confirm that you pass the same tests as in the notebook.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1647c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "img = mpimg.imread('resources/animal.jpg')\n",
    "imgplot = plt.imshow(img)\n",
    "imgplot.axes.get_xaxis().set_visible(False)\n",
    "imgplot.axes.get_yaxis().set_visible(False)\n",
    "print(\"Congratulations on finishing this lab!\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
