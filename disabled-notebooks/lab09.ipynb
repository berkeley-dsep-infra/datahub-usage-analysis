{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"lab09.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "title",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "# Lab 09: Probability and Modeling\n",
    "In this lab, you will\n",
    "\n",
    "1. Explore properties of random variables through the example of binomial distribution.\n",
    "1. Explore Central Limit Theorem (CLT) by simulation. \n",
    "1. Explore if the \"sample maximum\" is a biased estimator for the true maximum of a population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Due Date\n",
    "\n",
    "The on-time deadline is **Tuesday, March 21st, 11:59 PM PT**. Please read the syllabus for the grace period policy. No late submissions beyond the grace period will be accepted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab Walk-Through\n",
    "In addition to the lab notebook, we have also released a prerecorded walk-through video of the lab. We encourage you to reference this video as you work through the lab. Run the cell below to display the video.\n",
    "\n",
    "**Note**: The walkthrough video is partially recorded from Spring 2022, where this lab was labeled Lab 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo(\"_K7OvmRbb5w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaboration Policy\n",
    "Data science is a collaborative activity. While you may talk with others about this assignment, we ask that you **write your solutions individually**. If you discuss the assignment with others, please **include their names** in the cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Collaborators:** *list names here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "setup",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell to set up your notebook\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import seaborn as sns\n",
    "from IPython.display import FileLink, FileLinks\n",
    "FileLink('path_to_file/filename.extension')\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "sns.set_context(\"talk\")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(2023) # Do not change this line; this sets the pseudorandomness of the autograder.\n",
    "\n",
    "from IPython.display import display, Latex, Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "intro",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "<br/><br/>\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "# Question 1: Probability with Binomial Random Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Question 1a: Data Loading\n",
    "\n",
    "Berkeley Half Marathon is an annual weekend-long race here in Berkeley. \n",
    "\n",
    "Suppose that you want to collect a sample of participants to understand how many individuals of your sample also participated in the previous year's race.\n",
    "\n",
    "Let's first assume that we have access to the official data so we can simulate the potential result we might get (**in practice we don't!**). The dataset `marathon.csv` includes information for all racers who registered for the Berkeley Half Marathon. (Note: we artificially generated this data, but assume it is **the population data** as described). \n",
    "\n",
    "* The `Bib Number` of each participant (i.e., racer) is in order of registration â€” integers from $1$ to the total unknown number of participants. \n",
    "* The column `Race Type` denotes the type of race a participant is in.\n",
    "* The column `Experienced` denotes if a participant participated in race in the previous year.\n",
    "* The column `Dog Lover` denotes if a participant is a dog lover.\n",
    "\n",
    "Load the dataset `marathon.csv` into the DataFrame `marathon` and assign `true_prop` to the true proportion of experienced racers. \n",
    "\n",
    "**Hint:** The true proportion of experienced racer is the proportion of experienced racer in the population. We call numerical function of the population such as true proportion of racer a population parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "marathon = ...\n",
    "display(marathon.head())\n",
    "true_prop = ...\n",
    "true_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that you have access to the official roster and are able to collect a Simple Random Sample (SRS) of 100 racers. You decided to use the proportion of experienced racers in your sample as an estimate of the true proportion of experienced racers in the population. \n",
    "\n",
    "\n",
    "How would a sample proportion compare to the true proportion? Formally defined, let $X_1, \\dots, X_n$ be a sample of $n$ random variables from the population. Define the **sample proportion** as the fraction of the sample that is experienced racers. Note that each $X_i$'s is a boolean indicator random variable, where 1 if racer $i$ is experienced, and 0 if not. The sample proportion $\\hat{p}$ is therefore also the mean of the sample.\n",
    "\n",
    "$$\\hat{p} = \\text{sample proportion} = \\frac{1}{n}\\sum_{i=1}^{\\text{n}} X_i$$\n",
    "\n",
    "Note that **sample proportion** is a numerical function of the sample, so it is also a (sample) statistic. \n",
    "\n",
    "\n",
    "For the remainder of the lab, we will assume that the true population is large enough to simplify the sample as **a random sample with replacement.** With this assumption, $X_i$ can be drawn IID (Independent and Identically Distributed), with probability $p$ of being experienced. The sample proportion $\\hat{p}$ is then a Binomial random variable with expectation $\\mathbb{E}[\\hat{p}] = p$ and variance $\\text{Var}(\\hat{p}) = \\frac{p(1-p)}{n}$.\n",
    "\n",
    "In the remainder of this question, let's confirm these statistics through simulation.\n",
    "\n",
    "<br><br>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 1b: Expected Proportion\n",
    "Run 5000 independent simulations to compute the **proportion of experienced racers** in simulated samples of size $n = 100$, each generated uniformly at random from the true population `marathon`. You may assume that the true population is large enough such that the sample is a random sample with replacement. Assign `samples` to an array with 5000 elements, each of which is the proportion of experienced racers in that simulated sample. Also assign `simulated_mean` and `simulated_var` to the mean and variance of the simulated proportions, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "samples = ...\n",
    "simulated_mean = ...\n",
    "simulated_var = ...\n",
    "\n",
    "print(f\"[Mean]     Simulated: {simulated_mean:.5f}   Theoretical: {true_prop:.5f}\")\n",
    "print(f\"[Variance] Simulated: {simulated_var:.5f}   Theoretical: {true_prop*(1-true_prop)/100:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "What is a better way to support racers than passing out dog photos? :-) You decide to take a sample of size $n = 100$, where each racer will receive 1 dog photo if they are an experienced racer, 3 dog photos if they love dogs, and 4 dog photos if they are both an experienced racer and love dogs. What is the expected number of photos you need to print? \n",
    "\n",
    "Again, assume that the true population is large enough such that the sample is a random sample with replacement to simplify the problem, and that whether a racer loves dog and whether the racer participated in the previous year are independent. \n",
    "\n",
    "It can then be derived that the **expected number of photos** is: \n",
    "$$\\large 100 \\cdot p + 100 \\cdot 3 \\cdot q,$$ \n",
    "where $p$ is the true proportion of experienced racers and $q$ is the true proportion of dog lovers. This result follows from linearity of expectation:\n",
    "\n",
    "$$\\mathbb{E}[aX+bY] = a \\mathbb{E}[X] + b\\mathbb{E}[Y].$$\n",
    "\n",
    "The variance of the number of photos is:\n",
    "$$\\large 100 \\cdot p (1- p)+ 100 \\cdot 3^2 \\cdot q (1- q),$$\n",
    "which follows from the properties of variance and that the two samples are independent: \n",
    "\n",
    "$$\\text{Var}(aX+bY) = a^2\\text{Var}(X) + b^2\\text{Var}(Y) + 2 \\cdot a \\cdot b \\text{Cov}(X, Y) = a^2\\text{Var}(X) + b^2\\text{Var}(Y).$$\n",
    "\n",
    "\n",
    "<br><br>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 1c: Expectation and Variance of Linear Combination of Random Variables\n",
    "\n",
    "Confirm this result through simulation. Run 5000 independent simulations, where each simulation finds the number of **photos** needed for a sample of size $n = 100$ racers, selected uniformly at random (with replacement) from the true population `marathon`.  Assign `photo_samples` to an array with 5000 elements, each of which is the number of **photos** needed for the simulated sample. \n",
    "\n",
    "**Note:** We have computed `prop_dog_lover`, the true proportion of dog lover racers for you, so that you can verify that your simulated statistics match the theoretical statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prop_dog_lover = np.mean(marathon[\"Dog Lover\"])\n",
    "\n",
    "photo_samples = []\n",
    "...\n",
    "\n",
    "simulated_photos_mean = np.mean(photo_samples)\n",
    "simulated_photos_var = np.var(photo_samples)\n",
    "\n",
    "\n",
    "print(f\"[Mean]     Simulated: {simulated_photos_mean:.5f}    Theoretical: {(true_prop + 3*prop_dog_lover)*100:.5f}\")\n",
    "print(f\"[Variance] Simulated: {simulated_photos_var:.5f}   Theoretical: {100*true_prop*(1-true_prop) + 900*prop_dog_lover*(1-prop_dog_lover):.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "# Question 2: Central Limit Theorem\n",
    "\n",
    "Central limit theorem states that the distribution of the sample mean will converge to a normal distribution as sample size ($n$) goes to infinity. Let's see this in action!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 2a\n",
    "Complete the funtion `simulate`. The function `simulate` takes in one argument (`sample_size` the size of the sample) and returns a length 5000 list where each element is a proportion of experienced racers in a random sample of size `sample_size`. \n",
    "\n",
    "Then, use `simulate` to run 5000 independent simulations, where each simulation finds the proportion of **experienced racers** in a sample of size of 100, 500, and 1000 selected uniformly at random from the true population `marathon`. You may assume that the true population is large enough such that the sample is a random sample with replacement (note that in reality, our population is finite of size about 50k; this approximation becomes more inaccurate as our sample size grows larger). You should assign `samples100`, `samples500`, and `samples1000` each to arrays of 5000 elements with proportions of experienced racers of sample sizes **100**, **500**, and **1000**, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def simulate(sample_size):\n",
    "    ...\n",
    "\n",
    "samples100 = ...\n",
    "samples500 = ...\n",
    "samples1000 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<br><br>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 2b\n",
    "\n",
    "Recall that the normal distribution has a probability density function (pdf) of \n",
    "$$\\large\n",
    "N_\\sigma(x, \\mu) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\exp\\left(-\\frac{(x - \\mu)^2}{2  \\sigma ^2} \\right)\n",
    "$$\n",
    "\n",
    "Complete the function `gaussian` which returns the pdf of a normal distribution with mean `mean`, variance of `var`, at locations `x`. Hint: This is very similar to `gaussian_kernel` from Lab 04!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gaussian(mu, v, x):\n",
    "    \"\"\"\n",
    "    Compute the Gaussian density estimate for values in x\n",
    "\n",
    "    Args:\n",
    "        mu: the mean/center of the gaussian distribution\n",
    "        v: variance of the gussian distribution (width of the kernel)\n",
    "        x: observation\n",
    "\n",
    "    Returns:\n",
    "        The smoothed estimate at values of x\n",
    "    \"\"\"    \n",
    "    ...\n",
    "\n",
    "gaussian(0, 1, np.array([-1, 0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<br><br>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 2c\n",
    "\n",
    "We are ready to demonstrate the Central Limit Theorem visually, by comparing simulated distributions of sample means to the normal distribution. We have provided the skeleton code of an interactive plot. Fill in the blanks below using the `simulate` and `gaussian` functions from previous parts of this question.\n",
    "\n",
    "Then, in the cell below, describe the mean and spread of the sampling distribution, and how well they fit to the normal distribution as you increase sample size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "!jupyter nbextension enable --py widgetsnbextension\n",
    "\n",
    "def f(sample_size):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    # Generate the simulated proportions\n",
    "    sim_samples = ...\n",
    "    # Make a histogram plot of the simulated proportions. Set density to True and edgecolor to \"none\"\n",
    "    ...\n",
    "    x = np.linspace(0, 1, 1001)\n",
    "    # We provided the mean and variance for you. If you are intersted in knowing how to calculate these, take Data 140!\n",
    "    mean = true_prop\n",
    "    var = true_prop*(1-true_prop)/sample_size\n",
    "    # Compute the pdf of normal distribution of mean `mean` and variance `var` at locations x\n",
    "    y = ...\n",
    "    plt.plot(x, y, linewidth=1)\n",
    "    plt.xlim(0, 1);\n",
    "    plt.ylim(0, 35);\n",
    "    plt.show()\n",
    "interact(f, sample_size=(10, 1000, 10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>\n",
    "\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "# Question 3: Estimator for Population Max\n",
    "\n",
    "\n",
    "Now suppose that we do not have access to the official roster; instead, we only have one sample. Without the official roster, we do not know the population, and therefore do not know the total number of racers. However, we still want to estimate the total racers given an observed sample so we can prepare a dog photo for everyone. That is, we want to find an estimator for this population maximum.\n",
    "\n",
    "Recall that the `Bib Number` of each participant (i.e., racer) is in order of registrationâ€”integers from $1$ to the total unknown number of participants. You decide to construct a sample by recording the bib number of every racer you see on the street in a given time period, and use the maximum bib number in your sample as an estimator for the true maximum bib number (i.e., total number of particpants, assuming everyone who registered participated). Assume that a racer's bib number has no relation to their racing experience, so that you are equally likely to see any of bib number in your sample.\n",
    "\n",
    "**Is the sample maximum a good estimator for the population maximum?** We'll use simulation to explore in this part of the lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 3a\n",
    "\n",
    "Let's first again assume that we have access to the total number of participants (again, in practice we don't!). Find the **true population maximum** and assign it to `true_max`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "true_max = ...\n",
    "true_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to see the summary statistics of Bib Number, no further action needed.\n",
    "marathon.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 3b\n",
    "\n",
    "How would a sample maximum compare to the true maximum? Let $X_1, \\dots, X_n$ be a sample of $n$ random variables drawn IID (Independent and Identically Distributed) from the population. Define the **sample max** as the maximum value of the sample.\n",
    "\n",
    "$$\\text{sample max} = \\max (X_1, \\dots, X_n)$$\n",
    "\n",
    "\n",
    "Recall from [Data 8](https://inferentialthinking.com/chapters/10/3/Empirical_Distribution_of_a_Statistic.html) that we can get the empirical distribution of a statistic by **simulating**, or repeatedly sampling from the population.\n",
    "Suppose we compute the sample max as the **maximum bib number from observing the bib numbers of $n = 200$ random racers**. By repeating this process for many randomly selected samples, we get a simulated distribution of the sample max statistic.\n",
    "\n",
    "Assign `sample_maxes` to an array that contains 5,000 simulated sample maxes from samples of size $n = 200$, each sampled randomly **with replacement** from the population `marathon`. (Side note: We sample with replacement because while it suggests that we could see the same racer multiple times in our sample, it allows us to assume each individual in our sample is drawn IID from the population.)\n",
    "\n",
    "Some useful functions: `df.sample` ([link](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html)), `np.random.choice` ([link](https://numpy.org/doc/stable/reference/random/generated/numpy.random.choice.html)). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2_code",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "sample_maxes = ...\n",
    "for i in range(5000):\n",
    "    sample = ...\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Question 3c\n",
    "\n",
    "Plot the empirical distribution of the sample maximum that you generated in Question 3b. Your plot should look like the below plot. It should include both the average sample maximum and the true population maximum as vertical lines.\n",
    "\n",
    "<img src='images/sample_max_dist.png' width=\"600px\" />\n",
    "\n",
    "Visualization/plotting tips:\n",
    "* To plot a vertical line with specific linestyles, see the `plt.axvline` [documentation](https://matplotlib.org/3.5.1/api/_as_gen/matplotlib.pyplot.axvline.html).\n",
    "* To include a label in the legend, pass in `label=...` to the plot that you'd like to label ([example](https://matplotlib.org/3.5.1/gallery/pyplots/axline.html#sphx-glr-gallery-pyplots-axline-py)).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = [10, 6])\n",
    "bins = np.linspace(49000, 50750, 25) # For your plot\n",
    "\n",
    "avg_sample_maxes = ...\n",
    "...\n",
    "\n",
    "plt.legend();     # Show legend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Question 3d\n",
    "\n",
    "Recall from [Spring 2023 Lecture 17](https://ds100.org/sp23/lecture/lec17/) that an **unbiased estimator** is one where the expected value of the estimator is the parameter. For example, the sample mean $\\bar{X}_n$ is an unbiased estimator of the population mean $\\mu$ because $\\mathbb{E}[\\bar{X}_n] = \\mu$ by linearity of expectation.\n",
    "\n",
    "Based on your analysis in Question 3c, assign `q3d` to the most correct option out of the following; then in the second cell, **explain your choice.**\n",
    "\n",
    "1. The sample maximum is an unbiased estimator of the population maximum.\n",
    "1. The sample maximum overestimates the population maximum.\n",
    "1. The sample maximum underestimates the population maximum.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q3d = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "## Food for thought (optional):\n",
    "\n",
    "What if instead of the sample max, we use another estimator, $2\\bar{X_n}-1$?  This is a common approach for this kind of uniform data; if you are interested, simulate and visualize the results for this estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your optional visualization here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "finish",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "<br/><br/>\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Congratulations! You are finished with Lab 09!\n",
    "\n",
    "Here are some doggos photo as promised :) Stay tune for cat photos next week!\n",
    "\n",
    "<img src='images/Bento.jpg' width=\"262px\" /> <img src='images/Hera_Thor.jpg' width=\"398px\" /> \n",
    "**(From left to right) Bento, Hera and Thor.**\n",
    "\n",
    "<img src='images/Mazy_Bailey.jpg' width=\"455px\" /> <img src='images/Junior.jpg' width=\"209px\" /> \n",
    "**(From left to right) Mazy and Bailey, Junior.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(pdf=False, run_tests=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q1a": {
     "name": "q1a",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> marathon.shape == (50732, 4)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(true_prop, 0.24897500591342742)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1b": {
     "name": "q1b",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.isclose(simulated_mean, true_prop, atol=1e-2)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(simulated_var, true_prop*(1-true_prop)/100, atol=1e-4)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1c": {
     "name": "q1c",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.isclose(simulated_photos_mean, (true_prop + 3*prop_dog_lover)*100, atol=1)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(simulated_photos_var, 100*true_prop*(1-true_prop) + 900*prop_dog_lover*(1-prop_dog_lover), atol=5)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2a": {
     "name": "q2a",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.isclose(np.mean(samples100), 0.24898, atol=1e-2)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(np.mean(samples500), 0.24898, atol=1e-2)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(np.mean(samples1000), 0.24898, atol=1e-2)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2b": {
     "name": "q2b",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.allclose(gaussian(0, 1, np.array([-1, 0, 1])), np.array([0.24197072, 0.39894228, 0.24197072]))\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3a": {
     "name": "q3a",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> true_max == 50732\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3b": {
     "name": "q3b",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> len(sample_maxes) == 5000\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.mean(sample_maxes) <= true_max\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.max(sample_maxes) <= true_max\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3d": {
     "name": "q3d",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> q3d in [1, 2, 3]\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> q3d == 3\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
